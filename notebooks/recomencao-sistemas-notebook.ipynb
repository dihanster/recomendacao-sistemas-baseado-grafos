{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Codigo-Recomencao-Graph-Based.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LtGQ91G7sp6"
      },
      "source": [
        "# Recomendacao de Sistemas Baseado em Grafos\n",
        "### Análise de Algoritmos e Estrutura de Dados -  Profa. Dra. Lilian Berton\n",
        "### Nome: Willian Dihanster Gomes de Oliveira\n",
        "\n",
        "### Resumo:\n",
        "Recomendação de sistemas possuem diversas aplicações no mundo real e tem sido um tema de grande interesse para grandes empresas. Diversas abordagens já foram propostas, incluindo métodos baseados em grafos bipartidos, que são capazes de modelar a relação usuários e itens de forma prática e intuitiva. Assim, neste trabalho, foi realizada a implementação de um sistema de recomendação baseado em grafos para recomendação de filmes aos usuários de um site. Os resultados obtidos foram comparados com dois métodos clássicos (k-popularidade e aleatório) em termos de coverage e personalization e indicaram bons resultados.\n",
        "\n",
        "Referências (Código-fonte): <br>\n",
        "https://github.com/kurasaiteja/Github-Recommender-System\n",
        "https://github.com/statisticianinstilettos/recmetrics/blob/e8d9b39131999c484c4c98265f91e233be6ca4cb/recmetrics/metrics.py#L160"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o892JXI7sp_"
      },
      "source": [
        "## 1 - Leitura dos Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91jFe2xz7sqA"
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import scipy.sparse as sp\n",
        "import time\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAm92xaS7sqA",
        "outputId": "1d043d2a-4e26-490b-a0d3-150c5f5bce12"
      },
      "source": [
        "# Carrega o dataset de movies\n",
        "movies = pd.read_csv('./data/movies.csv', sep=',')\n",
        "movies['movieId'] = movies['movieId'] * 1000\n",
        "movie_ids = list(movies.movieId.unique()) \n",
        "print(movies.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   movieId                               title                                       genres\n",
            "0     1000                    Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
            "1     2000                      Jumanji (1995)                   Adventure|Children|Fantasy\n",
            "2     3000             Grumpier Old Men (1995)                               Comedy|Romance\n",
            "3     4000            Waiting to Exhale (1995)                         Comedy|Drama|Romance\n",
            "4     5000  Father of the Bride Part II (1995)                                       Comedy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mu7eIKN7sqC",
        "outputId": "ab482394-7698-4d31-c26a-2f97e2417a40"
      },
      "source": [
        "# Carrega o dataset de ratings\n",
        "ratings = pd.read_csv('./data/ratings.csv', sep=',')\n",
        "ratings['movieId'] =  ratings['movieId'] * 1000\n",
        "user_ids = list(ratings.userId.unique())\n",
        "print(ratings.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   userId  movieId  rating   timestamp\n",
            "0       1    31000     2.5  1260759144\n",
            "1       1  1029000     3.0  1260759179\n",
            "2       1  1061000     3.0  1260759182\n",
            "3       1  1129000     2.0  1260759185\n",
            "4       1  1172000     4.0  1260759205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dw6jyHE7sqD"
      },
      "source": [
        "train = pd.DataFrame()\n",
        "test = pd.DataFrame()\n",
        "\n",
        "for i in np.unique(ratings['userId']):\n",
        "    train = train.reset_index(drop=True)\n",
        "#    example_train, example_test = train_test_split(ratings[ratings['userId']==i].sort_values(by='timestamp'), train_size=0.9, shuffle=False)\n",
        "    example_train, example_test = train_test_split(ratings[ratings['userId']==i], train_size=0.7, shuffle=False)\n",
        "    example_train = example_train.reset_index(drop=True)\n",
        "    example_test = example_test.reset_index(drop=True)\n",
        "    \n",
        "    if len(train) == 0:\n",
        "        train = pd.DataFrame(example_train, columns=ratings.columns)\n",
        "        test = pd.DataFrame(example_test, columns=ratings.columns)\n",
        "    else:\n",
        "        train = pd.concat([train, example_train], axis=0, ignore_index=True)\n",
        "        test = pd.concat([test, example_test], axis=0, ignore_index=True)\n",
        "        \n",
        "ratings = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQgxYP4q7sqD"
      },
      "source": [
        "## 2 - Criacao do Grafo Bipartido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjx9Apt67sqE",
        "outputId": "6cfb69c6-4296-4af6-e45c-a51bd43fc6e7"
      },
      "source": [
        "# Criar um grafo\n",
        "print('Criando Grafo Bipartido...')\n",
        "G = nx.Graph()\n",
        "\n",
        "# Criar os nohs do grafo, onde nohs = user_ids e movies_ids\n",
        "G.add_nodes_from(user_ids, bipartite='users')\n",
        "G.add_nodes_from(movie_ids, bipartite='movies')\n",
        "\n",
        "# Cria as arestas do grafo, onde user_ids se relacionam com filmes\n",
        "# Dado que o grafo eh bipartido, user_ids soh se relacionam com filmes e vice-versa\n",
        "for name, group in ratings.groupby(['userId', 'movieId']):\n",
        "    userId, movieId = name\n",
        "    G.add_edges_from([(userId, movieId)])\n",
        "\n",
        "# Printa o numero de vertices e arestas\n",
        "print('Grafo Bipartido de Usuarios x Filmes criado!')\n",
        "print(f'Grafo possui {len(G.nodes())} nohs e {len(G.edges())} arestas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Criando Grafo Bipartido...\n",
            "Grafo Bipartido de Usuarios x Filmes criado!\n",
            "Grafo possui 9796 nohs e 69717 arestas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQxpWMxN7sqH"
      },
      "source": [
        "## 3 - Recomendador de Sistemas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_5LNC7X7sqH"
      },
      "source": [
        "### 3.1 - Nohs de uma Particao"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2CuiQx7sqI",
        "outputId": "512c0502-f910-48bf-ac41-6558183240d2"
      },
      "source": [
        "# Retorna todos os noh de uma particao\n",
        "def get_nodes_from_partition(G, partition):\n",
        "    nodes = []\n",
        "    \n",
        "    # Para cada noh no Grafo\n",
        "    for node in G.nodes():\n",
        "        # Se a particao do noh atual == partition, adicionamos o noh\n",
        "        if G.nodes[node]['bipartite'] == partition:\n",
        "            nodes.append(node)\n",
        "            \n",
        "    return nodes\n",
        "\n",
        "# Printa o numero de noh nas particoes\n",
        "print(len(get_nodes_from_partition(G, 'users')))\n",
        "print(len(get_nodes_from_partition(G, 'movies')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "671\n",
            "9125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWR-TSde7sqJ"
      },
      "source": [
        "### 3.2 - Filmes em Comum entre dois Nohs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UMb26g07sqJ",
        "outputId": "2e5cc030-3238-4e03-b2ae-f8425615b216"
      },
      "source": [
        "# Retorna filmes em comum entre dois nohs\n",
        "def shared_partition_nodes(G, node1, node2):\n",
        "    # Assegura que os nos estao na mesma particao\n",
        "    assert G.nodes[node1]['bipartite'] == G.nodes[node2]['bipartite']\n",
        "\n",
        "    # Pega os vizinhos dos nohs\n",
        "    nbrs1 = G.neighbors(node1)\n",
        "    nbrs2 = G.neighbors(node2)\n",
        "\n",
        "    # Calcula interseccao de de filmes entre os nohs\n",
        "    overlap = set(nbrs1).intersection(nbrs2)\n",
        "    return overlap\n",
        "\n",
        "# Printa os filmes em comum entre dois nohs\n",
        "node1 = 1\n",
        "node2 = 4\n",
        "print(f'Filmes em comum com o noh {node1} e noh {node2}:')\n",
        "for m in shared_partition_nodes(G, node1, node2):\n",
        "    print(np.array(movies[movies['movieId'] == m][['movieId', 'title']]).ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filmes em comum com o noh 1 e noh 4:\n",
            "[1371000 'Star Trek: The Motion Picture (1979)']\n",
            "[1953000 'French Connection, The (1971)']\n",
            "[2105000 'Tron (1982)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Gzlndk7sqK"
      },
      "source": [
        "### 3.3 - Calculando Similaridade entre Usuarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhZ3pQAy7sqL",
        "outputId": "6d3a99ac-1c96-489d-9169-59984162e142"
      },
      "source": [
        "# Retorna um coeficiente de similaridade entre dois nohs\n",
        "def user_similarity(G, user1, user2, movies_nodes):\n",
        "    # Assegura que os nohs sao da particao \"users\"\n",
        "    assert G.nodes[user1]['bipartite'] == 'users'\n",
        "    assert G.nodes[user2]['bipartite'] == 'users'\n",
        "\n",
        "    # Pega o conjunto de filmes compartilhados entre dois usuarios\n",
        "    shared_nodes = shared_partition_nodes(G, user1, user2)\n",
        "    \n",
        "    # Retorna o coeficiente de similaridade entre os nohs\n",
        "    # Dado pelo numero de filmes compartilhados pelo numero de filmes totais\n",
        "    return len(shared_nodes) / len(movies_nodes)\n",
        "\n",
        "# Computa o coeficiente de similaridade entre dois usuarios\n",
        "movies_nodes = get_nodes_from_partition(G, 'movies')\n",
        "node1, node2 = 1, 73\n",
        "similarity_score = user_similarity(G, node1, node2, movies_nodes)\n",
        "print(f'Score de Similaridade entre o noh {node1} e noh {node2} eh {similarity_score}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score de Similaridade entre o noh 1 e noh 73 eh 0.0012054794520547946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSzWxSmg7sqN",
        "outputId": "55c7613b-1e1a-45cf-b8e0-b1b2ffebde6c"
      },
      "source": [
        "# Retorna os usuarios mais similares a um noh\n",
        "def most_similar_users(G, user, user_nodes, proj_nodes):\n",
        "    # Assegura que o noh eh um 'user'\n",
        "    assert G.nodes[user]['bipartite'] == 'users'\n",
        "\n",
        "    # Pega todos os outros usuarios\n",
        "    user_nodes = set(user_nodes)\n",
        "    user_nodes.remove(user)\n",
        "\n",
        "    # Cria um dicionario de similaridades\n",
        "    similarities = defaultdict(list)\n",
        "    for node in user_nodes:\n",
        "        similarity = user_similarity(G, user, node, proj_nodes)\n",
        "        similarities[similarity].append(node)\n",
        "\n",
        "    # Calcula a maior similaridade\n",
        "    max_similarity = max(similarities.keys())\n",
        "    \n",
        "    # Retorna lista de usuarios com maior similaridade ao noh\n",
        "    return similarities[max_similarity]\n",
        "\n",
        "user_nodes = get_nodes_from_partition(G, 'users')\n",
        "movies_nodes = get_nodes_from_partition(G, 'movies')\n",
        "node1 = 1\n",
        "print(f'Usuarios mais similares ao noh {node1} sao: {most_similar_users(G, node1, user_nodes, movies_nodes)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usuarios mais similares ao noh 1 sao: [73, 468]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku-jqdAJ7sqN"
      },
      "source": [
        "### 3.4 - Recomendador de Filmes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "too7slu27sqN",
        "outputId": "47aa0012-715f-496e-abd7-d838df57381e"
      },
      "source": [
        "# Faz a recomendacao de filmes para um usuario, dado um usuario similar\n",
        "def recommend_movies(G, from_user, to_user):\n",
        "    # Pega os filmes que o usuario semelhante assistiu e os que o usuario assistiu\n",
        "    from_movies = set(G.neighbors(from_user))\n",
        "    to_movies = set(G.neighbors(to_user))\n",
        "\n",
        "    # Retorna os filmes que o usuario ainda nao assistiu, e o usuario semelhante sim\n",
        "    return from_movies.difference(to_movies)\n",
        "\n",
        "# Printa os filmes as serem recomendados\n",
        "node1, node2 = 1, 73\n",
        "print(f'Filmes recomendados ao noh {node1} sao: {recommend_movies(G, node1, node2)}')\n",
        "for m in recommend_movies(G, node1, node2):\n",
        "    print(np.array(movies[movies['movieId'] == m][['movieId', 'title']]).ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filmes recomendados ao noh 1 sao: {1172000, 1287000, 1371000}\n",
            "[1172000 'Cinema Paradiso (Nuovo cinema Paradiso) (1989)']\n",
            "[1287000 'Ben-Hur (1959)']\n",
            "[1371000 'Star Trek: The Motion Picture (1979)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqET4uyZ7sqO"
      },
      "source": [
        "### 3.5 - Metricas de Desempenho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne0BZwUl7sqO"
      },
      "source": [
        "def prediction_coverage(predicted, catalog):\n",
        "    predicted_flattened = [p for sublist in predicted for p in sublist]\n",
        "    unique_predictions = len(set(predicted_flattened))\n",
        "    prediction_coverage = round(unique_predictions/(len(catalog)* 1.0)*100, 2)\n",
        "    \n",
        "    return prediction_coverage\n",
        "\n",
        "def personalization(predicted):\n",
        "    predicted = np.array(predicted)\n",
        "    \n",
        "    df = pd.DataFrame(data=predicted).reset_index().melt(\n",
        "        id_vars='index', value_name='item',\n",
        "    )\n",
        "    \n",
        "    a = len(dic)\n",
        "    b = len(np.unique(train.movieId))\n",
        "    df = pd.DataFrame(np.zeros((a, b)), columns=list(np.unique(train.movieId)))\n",
        "    for d in dic:\n",
        "        for c in predicted[d-1]:\n",
        "            df.loc[df.index==d, c] = 1  \n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.fillna(0, inplace=True)\n",
        "    rec_matrix_sparse = sp.csr_matrix(df.values)\n",
        "    \n",
        "    similarity = cosine_similarity(X=rec_matrix_sparse, dense_output=False)\n",
        "    upper_right = np.triu_indices(similarity.shape[0], k=1)\n",
        "    personalization = 1 - np.mean(similarity[upper_right])\n",
        "    \n",
        "    return personalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTTmKiJt7sqO"
      },
      "source": [
        "### 3.5 - Uso dos Recomendadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whvfNIY_7sqP",
        "outputId": "5c7a4bbf-a12b-41de-998a-49d0248ff895"
      },
      "source": [
        "recommenders = ['Grafo', 'Aleatorio', 'Populares']\n",
        "\n",
        "for r in recommenders:\n",
        "    preds = []\n",
        "    trues = []\n",
        "    coverage = []\n",
        "    dic = {}\n",
        "    for id in np.unique(ratings.userId):\n",
        "        dic[id] = []\n",
        "    k = 10\n",
        "    \n",
        "    print(f'Iniciando recomendacao do tipo {r} com {k} recomendacoes')\n",
        "    inicio = time.time()\n",
        "    for d in np.unique(ratings.userId):\n",
        "        \n",
        "        if r == 'Grafo':\n",
        "            similars = most_similar_users(G, d, user_nodes, movies_nodes)\n",
        "            for s in similars:\n",
        "                movies_recommend = recommend_movies(G, d, s)\n",
        "                dic[d] += movies_recommend\n",
        "                \n",
        "            p = list(np.unique(dic[d]))\n",
        "        elif r == 'Aleatorio':\n",
        "            p = list(np.unique(movies['movieId']))\n",
        "        elif r == 'Populares':\n",
        "            p = list(ratings['movieId'].value_counts().sort_values(ascending=False)[0:k])\n",
        "            \n",
        "        random.shuffle(p)\n",
        "        preds.append(p[0:k]) \n",
        "        trues.append(list(test[test['userId']==d]['movieId']))\n",
        "    \n",
        "    fim = time.time()\n",
        "    print(f'Tempo gasto com recomendacao do tipo {r} = {fim-inicio}s')        \n",
        "\n",
        "    \n",
        "    cov = prediction_coverage(preds, np.unique(movies['movieId']))\n",
        "    ind_pers = personalization(preds)\n",
        "    print(f\"Resultados obtidos: \\n Coverage = {cov} e Indice de Personalizacao = {ind_pers}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iniciando recomendacao do tipo Grafo com 10 recomendacoes\n",
            "Tempo gasto com recomendacao do tipo Grafo = 9.815768003463745s\n",
            "Resultados obtidos: \n",
            " Coverage = 22.96 e Indice de Personalizacao = 0.9922962532824188\n",
            "Iniciando recomendacao do tipo Aleatorio com 10 recomendacoes\n",
            "Tempo gasto com recomendacao do tipo Aleatorio = 6.693778991699219s\n",
            "Resultados obtidos: \n",
            " Coverage = 52.44 e Indice de Personalizacao = 0.9989087350134573\n",
            "Iniciando recomendacao do tipo Populares com 10 recomendacoes\n",
            "Tempo gasto com recomendacao do tipo Populares = 3.2840988636016846s\n",
            "Resultados obtidos: \n",
            " Coverage = 0.11 e Indice de Personalizacao = 0.0029806259314457684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDQhGkd7sqP"
      },
      "source": [
        "## 4 - Conclusoes\n",
        "Neste trabalho objetivamos construir uma recomendador de sistemas, para recomendar filmes, em um modelo baseado em grafos bipartidos. Os resultados obtidos, dado as métricas de objetivo, foram bons, apresentando bons valores de \\textit{coverage} e \\textit{personalization}.\n",
        "\n",
        "Entretanto, com essas métricas, o modelo não foi melhor que o modelo Random. isso é esperado, dado a definição das métricas e o modelo Random, que é beneficiado pelas propriedades aleatórias. É esperado que o modelo Random tenha baixos resultados de acurácia, e com isso, o modelo Graph-based pode ser mais indicados.\n",
        "\n",
        "Dessa forma, mais experimentos, incluindo novas métricas poderiam ser realizados. Além disso, também pode ser testado novas métricas para cálculo de similaridade entre usuários, que é um dos principais \"parâmetros\" do algoritmo baseado em grafos bipartidos.\n",
        "\n"
      ]
    }
  ]
}